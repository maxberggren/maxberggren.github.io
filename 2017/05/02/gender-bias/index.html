<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>Gender bias in language – analysis of bigrams in a news text corpus</title>
  <meta name="description" content="Julia Silge recently wrote a blog post about co-occurances of words together with gendered pronouns. This made me dig up some old code that did the same, but...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://maxberggren.se/2017/05/02/gender-bias/">
  <link rel="alternate" type="application/atom+xml" title="MAX BERGGREN" href="http://maxberggren.se/feed.xml" />

  <!-- Font -->
  <link href='http://fonts.googleapis.com/css?family=Playfair+Display:400,700,900,400italic,700italic,900italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">

  <style>.async-hide { opacity: 0 !important} </style>
  <script>(function(a,s,y,n,c,h,i,d,e){s.className+=' '+y;h.start=1*new Date;
  h.end=i=function(){s.className=s.className.replace(RegExp(' ?'+y),'')};
  (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
  })(window,document.documentElement,'async-hide','dataLayer',4000,
  {'GTM-PG6BMF2':true});</script>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-698202-1', 'auto');
    ga('require', 'GTM-PG6BMF2');
    ga('send', 'pageview');
  </script>

  <!-- Mathjax -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true,
          processEnvironments: true
    }
  });
  MathJax.Hub.Configured();
  </script>

  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
  <script>

    hljs.configure({
      languages: [null]
    })
    hljs.initHighlightingOnLoad();

  </script>




  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/railscasts.min.css">


</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">MAX BERGGREN</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Gender bias in language – analysis of bigrams in a news text corpus</h1>
    <p class="post-meta">May 2, 2017</p>
  </header>

  <article class="post-content">
    <p>Julia Silge recently <a href="http://juliasilge.com/blog/Gender-Pronouns/">wrote</a> a blog post about co-occurances of words together with gendered pronouns. This made me dig up some old code that did the same, but with the difference that it also extends to gendered names besides pronouns. The data is a corpus of Swedish news texts, and I’ve used name statistics from Sweden Statistics (SCB) to parse out what names are male and female.</p>

<p>So let’s hack up a naive bookkeeping code to count all <a href="https://en.wikipedia.org/wiki/N-gram">bigrams</a> containing he/she/male_name/female_name. My corpus has already replaced all names with <code>female_name</code>/<code>male_name</code> since that’s what <a href="http://www.prognosis.se/">my gender monitor does</a>. I’ll use <code>textacy</code> for tokenization that uses the really fast <code>spaCy</code> behind the hoods. That said, this still takes some time to run. I did start to redo it in <code>dask</code>, but I realized that would take more time than to just let it run (see <a href="https://xkcd.com/1205/">appropiate xkcd</a>).</p>

<pre><code class="language-python"># For my unorthodox csv
import sys, csv
csv.field_size_limit(sys.maxsize)

# A counter for female and male connections
from collections import Counter
cnt = {'he': Counter(), 'she': Counter()}

import textacy
for d in textacy.fileio.read.read_csv('news_corpus.csv'):

    # Extract tokens
    doc = textacy.Doc(d[0].lower(), lang=u'sv')

    # Extract bigrams
    ngrams = textacy.extract.ngrams(
        doc, n=2,
        filter_stops=False,
        filter_punct=False,
        filter_nums=False)

    # Bookkeeping for all bigram findings
    for gram in ngrams:

        t0 = str(gram[0]) # First token in bigram
        t1 = str(gram[1]) # Second token in bigram

        if t0 == 'han':
            cnt['he'][t1] += 1
        elif t1 == 'han':
            cnt['he'][t0] += 1

        elif str(t0) == 'male_name':
            cnt['he'][t1] += 1
        elif str(t1) == 'male_name':
            cnt['he'][t0] += 1

        elif str(t0) == 'hon':
            cnt['she'][t1] += 1
        elif str(t1) == 'hon':
            cnt['she'][t0] += 1

        elif str(t0) == 'female_name':
            cnt['she'][t1] += 1
        elif str(t1) == 'female_name':
            cnt['she'][t0] += 1
</code></pre>

<p>Now <code>cnt['he']</code> and <code>cnt['she']</code> holds the frequencies for co-occurances of <em>he</em> and vice versa for <em>she</em>. But we want it to be in percent so we can compare. <a href="http://www.prognosis.se/">About 75 % of all mentions in news media are of males</a>, so we need to remove this bias to answer the question “How more often is word X used together with <em>he</em> rather than <em>she</em>”.</p>

<p>So let’s transform to percent and throw away some of the long tail to remove noise (keeping everything under percentile 95).</p>

<pre><code class="language-python">import pandas as pd
import numpy as np
</code></pre>

<pre><code class="language-python">he = (
    pd.DataFrame()
    .from_dict(cnt['he'], orient='index')
    .rename(columns={0: 'he'})
    .pipe(lambda d: d[d.he &gt; d.quantile(.95)['he']])
    .pipe(lambda d: d/d.sum())
    .sort_values('he', ascending=False)
)

she = (
    pd.DataFrame()
    .from_dict(cnt['she'], orient='index')
    .rename(columns={0: 'she'})
    .pipe(lambda d: d[d.she &gt; d.quantile(.95)['she']])
    .pipe(lambda d: d/d.sum())
    .sort_values('she', ascending=False)
)
</code></pre>

<p>For the male connected words that’s,</p>

<pre><code class="language-python">he.head(5)
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>he</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>.</th>
      <td>0.487862</td>
    </tr>
    <tr>
      <th>har</th>
      <td>0.066698</td>
    </tr>
    <tr>
      <th>är</th>
      <td>0.054389</td>
    </tr>
    <tr>
      <th>var</th>
      <td>0.033257</td>
    </tr>
    <tr>
      <th>–</th>
      <td>0.020974</td>
    </tr>
  </tbody>
</table>
</div>

<p>and for female connected words,</p>

<pre><code class="language-python">she.head(5)
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>she</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>.</th>
      <td>0.499746</td>
    </tr>
    <tr>
      <th>har</th>
      <td>0.073374</td>
    </tr>
    <tr>
      <th>är</th>
      <td>0.061925</td>
    </tr>
    <tr>
      <th>var</th>
      <td>0.027128</td>
    </tr>
    <tr>
      <th>&gt;</th>
      <td>0.019119</td>
    </tr>
  </tbody>
</table>
</div>

<p>holding what we are interested in. Except the punctuation, and also some emails.</p>

<pre><code class="language-python">odds = (
    # Joining
    he.merge(she, left_index=True, right_index=True)
    # Calc logodds
    .assign(logodds=lambda r: np.log2(r['she'] / r['he']))
    # Removing punctuation
    .pipe(lambda d: d[d.index.str.len() &gt; 1])
    # Removing emails
    .pipe(lambda d: d[~d.index.str.contains('@')])
    .pipe(lambda d: d[~d.index.str.contains('kundservice')])
    .sort_values('logodds', ascending=True)
)
</code></pre>

<p>Now let’s compare the ratios to find out what words are more used in connection to <code>she</code> and female names. We do this by joining/merging the <code>he</code> and <code>she</code> <code>DataFrame</code>s. Taking the log of this ratio conviniently centers the bias around zero – positive meaning skewed towards females and negative towards male.</p>

<h2 id="most-male-connected">Most male connected</h2>

<pre><code class="language-python">odds.query('logodds &lt; 0').head(50)
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>he</th>
      <th>she</th>
      <th>logodds</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>could</th>
      <td>0.002774</td>
      <td>0.001636</td>
      <td>-0.761978</td>
    </tr>
    <tr>
      <th>speaks</th>
      <td>0.002140</td>
      <td>0.001354</td>
      <td>-0.660601</td>
    </tr>
    <tr>
      <th>argues</th>
      <td>0.003989</td>
      <td>0.002594</td>
      <td>-0.620557</td>
    </tr>
    <tr>
      <th>explains</th>
      <td>0.002985</td>
      <td>0.002030</td>
      <td>-0.555968</td>
    </tr>
    <tr>
      <th>said</th>
      <td>0.004411</td>
      <td>0.003046</td>
      <td>-0.534531</td>
    </tr>
    <tr>
      <th>adds</th>
      <td>0.002325</td>
      <td>0.001636</td>
      <td>-0.507164</td>
    </tr>
    <tr>
      <th>wanted</th>
      <td>0.004015</td>
      <td>0.002876</td>
      <td>-0.481216</td>
    </tr>
    <tr>
      <th>gave</th>
      <td>0.001691</td>
      <td>0.001354</td>
      <td>-0.320751</td>
    </tr>
    <tr>
      <th>knows</th>
      <td>0.002087</td>
      <td>0.001692</td>
      <td>-0.302604</td>
    </tr>
    <tr>
      <th>continues</th>
      <td>0.003408</td>
      <td>0.002764</td>
      <td>-0.302231</td>
    </tr>
    <tr>
      <th>was</th>
      <td>0.033257</td>
      <td>0.027128</td>
      <td>-0.293883</td>
    </tr>
    <tr>
      <th>says</th>
      <td>0.005442</td>
      <td>0.004455</td>
      <td>-0.288434</td>
    </tr>
    <tr>
      <th>saying</th>
      <td>0.017143</td>
      <td>0.014100</td>
      <td>-0.282004</td>
    </tr>
    <tr>
      <th>saw</th>
      <td>0.001875</td>
      <td>0.001579</td>
      <td>-0.248106</td>
    </tr>
    <tr>
      <th>can</th>
      <td>0.005521</td>
      <td>0.004681</td>
      <td>-0.238034</td>
    </tr>
    <tr>
      <th>wrote</th>
      <td>0.003091</td>
      <td>0.002651</td>
      <td>-0.221490</td>
    </tr>
    <tr>
      <th>–</th>
      <td>0.020974</td>
      <td>0.018668</td>
      <td>-0.168022</td>
    </tr>
    <tr>
      <th>mentions</th>
      <td>0.002008</td>
      <td>0.001805</td>
      <td>-0.153641</td>
    </tr>
    <tr>
      <th>started</th>
      <td>0.001796</td>
      <td>0.001636</td>
      <td>-0.135196</td>
    </tr>
    <tr>
      <th>considers</th>
      <td>0.004675</td>
      <td>0.004286</td>
      <td>-0.125392</td>
    </tr>
    <tr>
      <th>had</th>
      <td>0.016668</td>
      <td>0.015961</td>
      <td>-0.062552</td>
    </tr>
    <tr>
      <th>sees</th>
      <td>0.005943</td>
      <td>0.005753</td>
      <td>-0.047070</td>
    </tr>
    <tr>
      <th>belives</th>
      <td>0.006102</td>
      <td>0.006035</td>
      <td>-0.015996</td>
    </tr>
    <tr>
      <th>wants</th>
      <td>0.011728</td>
      <td>0.011618</td>
      <td>-0.013629</td>
    </tr>
  </tbody>
</table>
</div>

<p>And positive gives skew towards females.</p>

<h2 id="most-female-connected">Most female connected</h2>

<pre><code class="language-python">odds.query('logodds &gt; 0').tail(50)
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>he</th>
      <th>she</th>
      <th>logodds</th>
    </tr>
    <tr>
      <th>index</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>takes</th>
      <td>0.003249</td>
      <td>0.003384</td>
      <td>0.058662</td>
    </tr>
    <tr>
      <th>come</th>
      <td>0.003830</td>
      <td>0.004004</td>
      <td>0.064124</td>
    </tr>
    <tr>
      <th>calls</th>
      <td>0.001453</td>
      <td>0.001523</td>
      <td>0.067814</td>
    </tr>
    <tr>
      <th>comes</th>
      <td>0.004253</td>
      <td>0.004512</td>
      <td>0.085297</td>
    </tr>
    <tr>
      <th>did</th>
      <td>0.002298</td>
      <td>0.002482</td>
      <td>0.110774</td>
    </tr>
    <tr>
      <th>means</th>
      <td>0.012019</td>
      <td>0.013141</td>
      <td>0.128750</td>
    </tr>
    <tr>
      <th>ska</th>
      <td>0.003698</td>
      <td>0.004061</td>
      <td>0.134928</td>
    </tr>
    <tr>
      <th>has</th>
      <td>0.066698</td>
      <td>0.073374</td>
      <td>0.137624</td>
    </tr>
    <tr>
      <th>notes</th>
      <td>0.003117</td>
      <td>0.003440</td>
      <td>0.142380</td>
    </tr>
    <tr>
      <th>goes</th>
      <td>0.001664</td>
      <td>0.001861</td>
      <td>0.161400</td>
    </tr>
    <tr>
      <th>pekar</th>
      <td>0.003196</td>
      <td>0.003609</td>
      <td>0.175423</td>
    </tr>
    <tr>
      <th>must</th>
      <td>0.001796</td>
      <td>0.002030</td>
      <td>0.176748</td>
    </tr>
    <tr>
      <th>became</th>
      <td>0.007370</td>
      <td>0.008347</td>
      <td>0.179618</td>
    </tr>
    <tr>
      <th>is</th>
      <td>0.054389</td>
      <td>0.061925</td>
      <td>0.187220</td>
    </tr>
    <tr>
      <th>holds</th>
      <td>0.001189</td>
      <td>0.001354</td>
      <td>0.187396</td>
    </tr>
    <tr>
      <th>got</th>
      <td>0.006551</td>
      <td>0.007896</td>
      <td>0.269373</td>
    </tr>
    <tr>
      <th>tells</th>
      <td>0.010170</td>
      <td>0.012351</td>
      <td>0.280359</td>
    </tr>
    <tr>
      <th>would</th>
      <td>0.003328</td>
      <td>0.004061</td>
      <td>0.286931</td>
    </tr>
    <tr>
      <th>took</th>
      <td>0.003011</td>
      <td>0.003722</td>
      <td>0.305790</td>
    </tr>
    <tr>
      <th>gets</th>
      <td>0.004042</td>
      <td>0.005019</td>
      <td>0.312632</td>
    </tr>
    <tr>
      <th>shows</th>
      <td>0.001902</td>
      <td>0.002369</td>
      <td>0.316679</td>
    </tr>
    <tr>
      <th>went</th>
      <td>0.002589</td>
      <td>0.003271</td>
      <td>0.337557</td>
    </tr>
    <tr>
      <th>”</th>
      <td>0.013815</td>
      <td>0.018047</td>
      <td>0.385547</td>
    </tr>
    <tr>
      <th>write</th>
      <td>0.005415</td>
      <td>0.007163</td>
      <td>0.403491</td>
    </tr>
    <tr>
      <th>does</th>
      <td>0.002853</td>
      <td>0.003779</td>
      <td>0.405488</td>
    </tr>
    <tr>
      <th>thinks</th>
      <td>0.004834</td>
      <td>0.006429</td>
      <td>0.411476</td>
    </tr>
    <tr>
      <th>as</th>
      <td>0.002430</td>
      <td>0.003271</td>
      <td>0.428705</td>
    </tr>
    <tr>
      <th>dies</th>
      <td>0.001030</td>
      <td>0.001410</td>
      <td>0.452740</td>
    </tr>
    <tr>
      <th>describes</th>
      <td>0.003698</td>
      <td>0.005076</td>
      <td>0.456856</td>
    </tr>
    <tr>
      <th>told</th>
      <td>0.001294</td>
      <td>0.001805</td>
      <td>0.479576</td>
    </tr>
    <tr>
      <th>born</th>
      <td>0.001479</td>
      <td>0.002087</td>
      <td>0.496385</td>
    </tr>
    <tr>
      <th>laughs</th>
      <td>0.000898</td>
      <td>0.001297</td>
      <td>0.530385</td>
    </tr>
    <tr>
      <th>lets</th>
      <td>0.000925</td>
      <td>0.001354</td>
      <td>0.549966</td>
    </tr>
    <tr>
      <th>feels</th>
      <td>0.001347</td>
      <td>0.001974</td>
      <td>0.551144</td>
    </tr>
    <tr>
      <th>and</th>
      <td>0.003381</td>
      <td>0.005132</td>
      <td>0.602081</td>
    </tr>
    <tr>
      <th>sits</th>
      <td>0.001875</td>
      <td>0.002876</td>
      <td>0.616964</td>
    </tr>
    <tr>
      <th>gives</th>
      <td>0.001691</td>
      <td>0.002764</td>
      <td>0.708996</td>
    </tr>
    <tr>
      <th>asked</th>
      <td>0.000766</td>
      <td>0.001297</td>
      <td>0.759867</td>
    </tr>
    <tr>
      <th>remembers</th>
      <td>0.000819</td>
      <td>0.001410</td>
      <td>0.783946</td>
    </tr>
    <tr>
      <th>lifts</th>
      <td>0.001242</td>
      <td>0.002200</td>
      <td>0.825100</td>
    </tr>
    <tr>
      <th>lives</th>
      <td>0.001294</td>
      <td>0.002425</td>
      <td>0.905841</td>
    </tr>
    <tr>
      <th>becomes</th>
      <td>0.001426</td>
      <td>0.004230</td>
      <td>1.568217</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="pick-out-the-most-skewed-words-for-plotting">Pick out the most skewed words for plotting</h2>

<pre><code class="language-python">headsntails = pd.concat([
    odds.head(30).query('logodds &lt; 0'),
    odds.tail(30).query('logodds &gt; 0')
], axis=0)

# Some styling
%matplotlib inline
%config InlineBackend.figure_formats = {'png', 'retina'}
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_palette("Paired", 15, .75)
sns.set_context("notebook", font_scale=1.2, rc={"lines.linewidth": 1.2})
sns.set_style("whitegrid")
custom_style = {
            'grid.color': '0.7',
            'grid.linestyle': '--',
            'grid.linewidth': 0.5,
}
sns.set_style(custom_style)

f, ax = plt.subplots(figsize=(8, 12))
x = [s.decode('utf-8') for s in headsntails['logodds'].index]
y = headsntails['logodds'].values

sns.barplot(y, x, palette="RdBu_r", ax=ax)

labels = [
    '{}x'.format(round(2**item, 1))
    for item in ax.get_xticks()
]
ax.set_xticklabels(labels)
ax.set_xlabel("Female usage")

for bar in ax.patches:
    smaller = 0.3
    height = bar.get_height()
    bar.set_height(height*smaller)
    move = height*(1-smaller)
    y = bar.get_y()
    bar.set_y(y+move)

# Finalize the plot
sns.despine(offset=5)
</code></pre>

<p><img src="/assets/gender_4-svd_19_0.png" alt="png" /></p>

<p>So men speaks, explains, says, thinks, [speaking punctuation] and statues. While women tells, describes, remembers, feels, live, recieves and sits. It’s clear that language is a mirror of what kind of values our society holds. Men are in news texts, other than just in real numbers more present – more in focus. More active and in the role as an expert. SAD!</p>

  </article>

  
  <div id="disqus_thread"></div>
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'maxberggren'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  
</div>

      </div>
    </div>

    <!--
<footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">MAX BERGGREN</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>MAX BERGGREN</li>
          <li><a href="mailto:maxberggren@gmail.com">maxberggren@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/maxberggren">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">maxberggren</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/maxberggren">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">maxberggren</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text"></p>
      </div>
    </div>

  </div>

</footer>
-->


  </body>

</html>
